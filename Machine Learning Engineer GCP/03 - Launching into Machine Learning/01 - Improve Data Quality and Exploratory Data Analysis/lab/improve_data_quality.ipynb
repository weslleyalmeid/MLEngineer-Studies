{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNdWfPXCjTjY"
   },
   "source": [
    "# Improving Data Quality\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "\n",
    "1. Resolve missing values\n",
    "2. Convert the Date feature column to a datetime format\n",
    "3. Rename a feature column, remove a value from a feature column\n",
    "4. Create one-hot encoding features\n",
    "5. Understand temporal feature conversions \n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "Recall that machine learning models can only consume numeric data, and that numeric data should be \"1\"s or \"0\"s.  Data is said to be \"messy\" or \"untidy\" if it is missing attribute values, contains noise or outliers, has duplicates, wrong data, upper/lower case column names, and is essentially not ready for ingestion by a machine learning algorithm.  \n",
    "\n",
    "This notebook presents and solves some of the most common issues of \"untidy\" data.  Note that different problems will require different methods, and they are beyond the scope of this notebook.\n",
    "\n",
    "Each learning objective will correspond to a _#TODO_ in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/launching_into_ml/solutions/improve_data_quality.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxyBFc_kKazA"
   },
   "source": [
    "Start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.3.4\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary tensorflow library and printing the TF version.\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd  # First, we'll import Pandas, a data processing and CSV file I/O library\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is based on California's [Vehicle Fuel Type Count by Zip Code](https://data.ca.gov/dataset/vehicle-fuel-type-count-by-zip-codeSynthetic) report.  The dataset has been modified to make the data \"untidy\" and is thus a synthetic representation that can be used for learning purposes.  \n",
    "  \n",
    "Let's download the raw .csv data by copying the data from a cloud storage bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"../data/transport\"):\n",
    "    os.makedirs(\"../data/transport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-training/mlongcp/v3.0_MLonGC/toy_data/untidy_vehicle_data_toy.csv...\n",
      "/ [1 files][ 23.7 KiB/ 23.7 KiB]                                                \n",
      "Operation completed over 1 objects/23.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://cloud-training/mlongcp/v3.0_MLonGC/toy_data/untidy_vehicle_data_toy.csv ../data/transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "-rw-r--r-- 1 jupyter jupyter 24263 Mar 15 22:20 untidy_vehicle_data_toy.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data/transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM6-n6xntv3t"
   },
   "source": [
    "Next, let's read in the dataset just copied from the cloud storage bucket and create a Pandas DataFrame.  We also add a Pandas .head() function to show you the top 5 rows of data in the DataFrame. Head() and Tail() are \"best-practice\" functions used to investigate datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "REZ57BXCLdfG",
    "outputId": "a6ef2eda-c7eb-4e2d-92e4-e7fcaa20b0af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Make</th>\n",
       "      <th>Light_Duty</th>\n",
       "      <th>Vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>&lt;2006</td>\n",
       "      <td>Diesel and Diesel Hybrid</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Zip Code Model Year                      Fuel       Make  \\\n",
       "0  10/1/2018   90000.0       2006                  Gasoline  OTHER/UNK   \n",
       "1  10/1/2018       NaN       2014                  Gasoline        NaN   \n",
       "2        NaN   90000.0        NaN                  Gasoline  OTHER/UNK   \n",
       "3  10/1/2018   90000.0       2017                  Gasoline  OTHER/UNK   \n",
       "4  10/1/2018   90000.0      <2006  Diesel and Diesel Hybrid  OTHER/UNK   \n",
       "\n",
       "  Light_Duty  Vehicles  \n",
       "0        NaN       1.0  \n",
       "1        Yes       1.0  \n",
       "2        Yes       NaN  \n",
       "3        Yes       1.0  \n",
       "4         No      55.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transport = pd.read_csv('../data/transport/untidy_vehicle_data_toy.csv')\n",
    "df_transport.head() # Output the first five rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Column Data Types\n",
    "\n",
    "DataFrames may have heterogenous or \"mixed\" data types, that is, some columns are numbers, some are strings, and some are dates etc. Because CSV files do not contain information on what data types are contained in each column, Pandas infers the data types when loading the data, e.g. if a column contains only numbers, Pandas will set that column’s data type to numeric: integer or float.\n",
    "\n",
    "Run the next cell to see information on the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499 entries, 0 to 498\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Date        497 non-null    object \n",
      " 1   Zip Code    497 non-null    float64\n",
      " 2   Model Year  497 non-null    object \n",
      " 3   Fuel        497 non-null    object \n",
      " 4   Make        496 non-null    object \n",
      " 5   Light_Duty  496 non-null    object \n",
      " 6   Vehicles    496 non-null    float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 27.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_transport.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what the .info() function shows us, we have six string objects and one float object.  Let's print out the first and last five rows of each column. We can definitely see more of the \"string\" object values now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Zip Code Model Year                      Fuel       Make  \\\n",
      "0    10/1/2018   90000.0       2006                  Gasoline  OTHER/UNK   \n",
      "1    10/1/2018       NaN       2014                  Gasoline        NaN   \n",
      "2          NaN   90000.0        NaN                  Gasoline  OTHER/UNK   \n",
      "3    10/1/2018   90000.0       2017                  Gasoline  OTHER/UNK   \n",
      "4    10/1/2018   90000.0      <2006  Diesel and Diesel Hybrid  OTHER/UNK   \n",
      "..         ...       ...        ...                       ...        ...   \n",
      "494  12/3/2018   90002.0       2010                  Gasoline     Type_I   \n",
      "495  12/4/2018   90002.0       2010                  Gasoline     Type_B   \n",
      "496  12/5/2018   90002.0       2010                  Gasoline     Type_C   \n",
      "497  12/6/2018   90002.0       2010                  Gasoline     Type_J   \n",
      "498  12/7/2018   90002.0       2010                  Gasoline     Type_J   \n",
      "\n",
      "    Light_Duty  Vehicles  \n",
      "0          NaN       1.0  \n",
      "1          Yes       1.0  \n",
      "2          Yes       NaN  \n",
      "3          Yes       1.0  \n",
      "4           No      55.0  \n",
      "..         ...       ...  \n",
      "494        Yes      11.0  \n",
      "495        Yes      58.0  \n",
      "496        Yes      45.0  \n",
      "497        Yes      82.0  \n",
      "498        Yes      12.0  \n",
      "\n",
      "[499 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_transport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics \n",
    "\n",
    "At this point, we have only one column which contains a numerical value (e.g. Vehicles).  For features which contain numerical values, we are often interested in various statistical measures relating to those values.  We can use .describe() to see some summary statistics for the numeric fields in our dataframe. Note, that because we only have one numeric feature, we see only one summary stastic - for now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>497.00000</td>\n",
       "      <td>496.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89838.23340</td>\n",
       "      <td>74.512097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3633.35609</td>\n",
       "      <td>243.839871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9001.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90001.00000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>90001.00000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90001.00000</td>\n",
       "      <td>56.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90002.00000</td>\n",
       "      <td>3178.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Zip Code     Vehicles\n",
       "count    497.00000   496.000000\n",
       "mean   89838.23340    74.512097\n",
       "std     3633.35609   243.839871\n",
       "min     9001.00000     1.000000\n",
       "25%    90001.00000    14.000000\n",
       "50%    90001.00000    25.000000\n",
       "75%    90001.00000    56.250000\n",
       "max    90002.00000  3178.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transport.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate a bit more of our data by using the .groupby() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Make</th>\n",
       "      <th>Light_Duty</th>\n",
       "      <th>Vehicles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Battery Electric</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>&lt;2006</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diesel and Diesel Hybrid</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>&lt;2006</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flex-Fuel</th>\n",
       "      <td>10/14/2018</td>\n",
       "      <td>90001.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>Type_A</td>\n",
       "      <td>Yes</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gasoline</th>\n",
       "      <td>10/1/2018</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid Gasoline</th>\n",
       "      <td>10/24/2018</td>\n",
       "      <td>90001.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natural Gas</th>\n",
       "      <td>10/25/2018</td>\n",
       "      <td>90001.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>10/8/2018</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>&lt;2006</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plug-in Hybrid</th>\n",
       "      <td>11/2/2018</td>\n",
       "      <td>90001.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>OTHER/UNK</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date  Zip Code Model Year       Make  \\\n",
       "Fuel                                                                   \n",
       "Battery Electric           10/1/2018   90000.0      <2006  OTHER/UNK   \n",
       "Diesel and Diesel Hybrid   10/1/2018   90000.0      <2006  OTHER/UNK   \n",
       "Flex-Fuel                 10/14/2018   90001.0       2007     Type_A   \n",
       "Gasoline                   10/1/2018   90000.0       2006  OTHER/UNK   \n",
       "Hybrid Gasoline           10/24/2018   90001.0       2009  OTHER/UNK   \n",
       "Natural Gas               10/25/2018   90001.0       2009  OTHER/UNK   \n",
       "Other                      10/8/2018   90000.0      <2006  OTHER/UNK   \n",
       "Plug-in Hybrid             11/2/2018   90001.0       2012  OTHER/UNK   \n",
       "\n",
       "                         Light_Duty  Vehicles  \n",
       "Fuel                                           \n",
       "Battery Electric                 No       4.0  \n",
       "Diesel and Diesel Hybrid         No      55.0  \n",
       "Flex-Fuel                       Yes      78.0  \n",
       "Gasoline                        Yes       1.0  \n",
       "Hybrid Gasoline                 Yes      18.0  \n",
       "Natural Gas                      No       2.0  \n",
       "Other                           Yes       6.0  \n",
       "Plug-in Hybrid                  Yes       1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transport.groupby('Fuel').first() # Get the first entry for each month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Missing Values\n",
    "\n",
    "Missing values adversely impact data quality, as they can lead the machine learning model to make inaccurate inferences about the data. Missing values can be the result of numerous factors, e.g. \"bits\" lost during streaming transmission, data entry, or perhaps a user forgot to fill in a field.  Note that Pandas recognizes both empty cells and “NaN” types as missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the null values for all features in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          2\n",
       "Zip Code      2\n",
       "Model Year    2\n",
       "Fuel          2\n",
       "Make          3\n",
       "Light_Duty    3\n",
       "Vehicles      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transport.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see a sampling of which values are missing, enter the feature column name.  You'll notice that \"False\" and \"True\" correpond to the presence or abscence of a value by index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      10/1/2018\n",
      "1      10/1/2018\n",
      "2            NaN\n",
      "3      10/1/2018\n",
      "4      10/1/2018\n",
      "         ...    \n",
      "494    12/3/2018\n",
      "495    12/4/2018\n",
      "496    12/5/2018\n",
      "497    12/6/2018\n",
      "498    12/7/2018\n",
      "Name: Date, Length: 499, dtype: object\n",
      "0      False\n",
      "1      False\n",
      "2       True\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "494    False\n",
      "495    False\n",
      "496    False\n",
      "497    False\n",
      "498    False\n",
      "Name: Date, Length: 499, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print (df_transport['Date'])\n",
    "print (df_transport['Date'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      OTHER/UNK\n",
      "1            NaN\n",
      "2      OTHER/UNK\n",
      "3      OTHER/UNK\n",
      "4      OTHER/UNK\n",
      "         ...    \n",
      "494       Type_I\n",
      "495       Type_B\n",
      "496       Type_C\n",
      "497       Type_J\n",
      "498       Type_J\n",
      "Name: Make, Length: 499, dtype: object\n",
      "0      False\n",
      "1       True\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "494    False\n",
      "495    False\n",
      "496    False\n",
      "497    False\n",
      "498    False\n",
      "Name: Make, Length: 499, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print (df_transport['Make'])\n",
    "print (df_transport['Make'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2006\n",
      "1       2014\n",
      "2        NaN\n",
      "3       2017\n",
      "4      <2006\n",
      "       ...  \n",
      "494     2010\n",
      "495     2010\n",
      "496     2010\n",
      "497     2010\n",
      "498     2010\n",
      "Name: Model Year, Length: 499, dtype: object\n",
      "0      False\n",
      "1      False\n",
      "2       True\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "494    False\n",
      "495    False\n",
      "496    False\n",
      "497    False\n",
      "498    False\n",
      "Name: Model Year, Length: 499, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print (df_transport['Model Year'])\n",
    "print (df_transport['Model Year'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we deduce about the data at this point?\n",
    "\n",
    "First, let's summarize our data by row, column, features, unique, and missing values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows     :  499\n",
      "Columns  :  7\n",
      "\n",
      "Features : \n",
      " ['Date', 'Zip Code', 'Model Year', 'Fuel', 'Make', 'Light_Duty', 'Vehicles']\n",
      "\n",
      "Unique values :  \n",
      " Date          130\n",
      "Zip Code        4\n",
      "Model Year     15\n",
      "Fuel            8\n",
      "Make           43\n",
      "Light_Duty      2\n",
      "Vehicles      151\n",
      "dtype: int64\n",
      "\n",
      "Missing values :   17\n"
     ]
    }
   ],
   "source": [
    "print (\"Rows     : \" ,df_transport.shape[0])\n",
    "print (\"Columns  : \" ,df_transport.shape[1])\n",
    "print (\"\\nFeatures : \\n\" ,df_transport.columns.tolist())\n",
    "print (\"\\nUnique values :  \\n\",df_transport.nunique())\n",
    "print (\"\\nMissing values :  \", df_transport.isnull().sum().values.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the data again -- this time the last five rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Make</th>\n",
       "      <th>Light_Duty</th>\n",
       "      <th>Vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>12/3/2018</td>\n",
       "      <td>90002.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Type_I</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>12/4/2018</td>\n",
       "      <td>90002.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Type_B</td>\n",
       "      <td>Yes</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>12/5/2018</td>\n",
       "      <td>90002.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Type_C</td>\n",
       "      <td>Yes</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>12/6/2018</td>\n",
       "      <td>90002.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Type_J</td>\n",
       "      <td>Yes</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>12/7/2018</td>\n",
       "      <td>90002.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Type_J</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Zip Code Model Year      Fuel    Make Light_Duty  Vehicles\n",
       "494  12/3/2018   90002.0       2010  Gasoline  Type_I        Yes      11.0\n",
       "495  12/4/2018   90002.0       2010  Gasoline  Type_B        Yes      58.0\n",
       "496  12/5/2018   90002.0       2010  Gasoline  Type_C        Yes      45.0\n",
       "497  12/6/2018   90002.0       2010  Gasoline  Type_J        Yes      82.0\n",
       "498  12/7/2018   90002.0       2010  Gasoline  Type_J        Yes      12.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transport.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Are Our Data Quality Issues?\n",
    "\n",
    "1. **Data Quality Issue #1**:  \n",
    "> **Missing Values**:\n",
    "Each feature column has multiple missing values.  In fact, we have a total of 18 missing values.\n",
    "2. **Data Quality Issue #2**: \n",
    "> **Date DataType**:  Date is shown as an \"object\" datatype and should be a datetime.  In addition, Date is in one column.  Our business requirement is to see the Date parsed out to year, month, and day.  \n",
    "3. **Data Quality Issue #3**: \n",
    "> **Model Year**: We are only interested in years greater than 2006, not \"<2006\".\n",
    "4. **Data Quality Issue #4**:  \n",
    "> **Categorical Columns**:  The feature column \"Light_Duty\" is categorical and has a \"Yes/No\" choice.  We cannot feed values like this into a machine learning model.  In addition, we need to \"one-hot encode the remaining \"string\"/\"object\" columns.\n",
    "5. **Data Quality Issue #5**:  \n",
    "> **Temporal Features**:  How do we handle year, month, and day?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issue #1:  \n",
    "##### Resolving Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most algorithms do not accept missing values.  Yet, when we see missing values in our dataset, there is always a tendency to just \"drop all the rows\" with missing values.  Although Pandas will fill in the blank space with “NaN\", we should \"handle\" them in some way.\n",
    "\n",
    "While all the methods to handle missing values is beyond the scope of this lab, there are a few methods you should consider.  For numeric columns, use the \"mean\" values to fill in the missing numeric values.  For categorical columns, use the \"mode\" (or most frequent values) to fill in missing categorical values. \n",
    "\n",
    "In this lab, we use the .apply and Lambda functions to fill every column with its own most frequent value.  You'll learn more about Lambda functions later in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again for missing values by showing how many rows contain NaN values for each feature column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #1a:** Check for missing values by showing how many rows contain NaN values for each feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          2\n",
       "Zip Code      2\n",
       "Model Year    2\n",
       "Fuel          2\n",
       "Make          3\n",
       "Light_Duty    3\n",
       "Vehicles      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO 1a\n",
    "# TODO -- Your code here.\n",
    "df_transport.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab Task #1b: Apply the lambda function.**Lab Task #1b:** Apply the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25352/414166016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO 1b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TODO -- Your code here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_transport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_transport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25352/414166016.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO 1b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TODO -- Your code here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_transport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_transport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4603\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4604\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# TODO 1b\n",
    "# TODO -- Your code here.\n",
    "df_transport = df_transport.apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #1c:** Check again for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 499 entries, 0 to 498\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Date        497 non-null    object \n",
      " 1   Zip Code    497 non-null    float64\n",
      " 2   Model Year  497 non-null    object \n",
      " 3   Fuel        497 non-null    object \n",
      " 4   Make        496 non-null    object \n",
      " 5   Light_Duty  496 non-null    object \n",
      " 6   Vehicles    496 non-null    float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 27.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO 1c\n",
    "# TODO -- Your code here.\n",
    "df_transport.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issue #2:  \n",
    "##### Convert the Date Feature Column to a Datetime Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date column is indeed shown as a string object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #2a:** Convert the datetime datatype with the to_datetime() function in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2a\n",
    "# TODO -- Your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #2b:** Show the converted Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2b\n",
    "# TODO -- Your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse Date into three columns, e.g. year, month, and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transport['year'] = df_transport['Date'].dt.year\n",
    "df_transport['month'] = df_transport['Date'].dt.month\n",
    "df_transport['day'] = df_transport['Date'].dt.day\n",
    "#df['hour'] = df['date'].dt.hour - you could use this if your date format included hour.\n",
    "#df['minute'] = df['date'].dt.minute - you could use this if your date format included minute.\n",
    "df_transport.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's confirm the Date parsing.  This will also give us a another visualization of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are creating a new dataframe called \"grouped_data\" and grouping by on the column \"Make\"\n",
    "grouped_data = df_transport.groupby(['Make'])\n",
    "\n",
    "# Get the first entry for each month.\n",
    "df_transport.groupby('month').first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have Dates as a integers, let's do some additional plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.jointplot(x='month',y='Vehicles',data=df_transport)\n",
    "#plt.title('Vehicles by Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issue #3:  \n",
    "##### Rename a Feature Column and Remove a Value.  \n",
    "\n",
    "Our feature columns have different \"capitalizations\" in their names, e.g. both upper and lower \"case\".  In addition, there are \"spaces\" in some of the column names.  In addition, we are only interested in years greater than 2006, not \"<2006\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #3a:** Remove all the spaces for feature columns by renaming them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3a\n",
    "# TODO -- Your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Note:** Next we create a copy of the dataframe to avoid the \"SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\" warning.  Run the cell to remove the value '<2006' from the modelyear feature column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #3b:** Create a copy of the dataframe to avoid copy warning issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 3b\n",
    "# TODO -- Your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, confirm that the modelyear value '<2006' has been removed by doing a value count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['modelyear'].value_counts(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issue #4:  \n",
    "##### Handling Categorical Columns\n",
    "\n",
    "The feature column \"lightduty\" is categorical and has a \"Yes/No\" choice.  We cannot feed values like this into a machine learning model.  We need to convert the binary answers from strings of yes/no to integers of 1/0.  There are various methods to achieve this.  We will use the \"apply\" method with a lambda expression.  Pandas. apply() takes a function and applies it to all values of a Pandas series.\n",
    "\n",
    "##### What is a Lambda Function?\n",
    "\n",
    "Typically, Python requires that you define a function using the def keyword. However, lambda functions are anonymous -- which means there is no need to name them. The most common use case for lambda functions is in code that requires a simple one-line function (e.g. lambdas only have a single expression).  \n",
    "\n",
    "As you progress through the Course Specialization, you will see many examples where lambda functions are being used.  Now is a good time to become familiar with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets count the number of \"Yes\" and\"No's\" in the 'lightduty' feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lightduty'].value_counts(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the Yes to 1 and No to 0. Pandas. apply()  . apply takes a function and applies it to all values of a Pandas series (e.g. lightduty). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'lightduty'] = df['lightduty'].apply(lambda x: 0 if x=='No' else 1)\n",
    "df['lightduty'].value_counts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that \"lightduty\" has been converted.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding Categorical Feature Columns\n",
    "\n",
    "Machine learning algorithms expect input vectors and not categorical features. Specifically, they cannot handle text or string values.  Thus, it is often useful to transform categorical features into vectors.\n",
    "\n",
    "One transformation method is to create dummy variables for our categorical features.  Dummy variables are a set of binary (0 or 1) variables that each represent a single class from a categorical feature.  We simply  encode the categorical variable as a one-hot vector, i.e. a vector where only one element is non-zero, or hot.  With one-hot encoding, a categorical feature becomes an array whose size is the number of possible choices for that feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panda provides a function called \"get_dummies\" to convert a categorical variable into dummy/indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dummy variables for categorical data with more inputs.  \n",
    "\n",
    "data_dummy = pd.get_dummies(df[['zipcode','modelyear', 'fuel', 'make']], drop_first=True)\n",
    "data_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #4a:** Merge (concatenate) original data frame with 'dummy' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4a\n",
    "# TODO -- Your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #4b:** Drop attributes for which we made dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4b\n",
    "# TODO -- Your code here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that 'zipcode','modelyear', 'fuel', and 'make' have been dropped.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Issue #5:  \n",
    "##### Temporal Feature Columns\n",
    "\n",
    "Our dataset now contains year, month, and day feature columns.  Let's convert the month and day feature columns to meaningful representations as a way to get us thinking about changing temporal features -- as they are sometimes overlooked.  \n",
    "\n",
    "Note that the Feature Engineering course in this Specialization will provide more depth on methods to handle year, month, day, and hour feature columns.\n",
    "\n",
    "First, let's print the unique values for \"month\" and \"day\" in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Unique values of month:',df.month.unique())\n",
    "print ('Unique values of day:',df.day.unique())\n",
    "print ('Unique values of year:',df.year.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we map each temporal variable onto a circle such that the lowest value for that variable appears right next to the largest value. We compute the x- and y- component of that point using sin and cos trigonometric functions.   Don't worry, this is the last time we will use this code, as you can develop an input pipeline to address these temporal feature columns in TensorFlow and Keras - and it is much easier!  But, sometimes you need to appreciate what you're not going to encounter as you move through the course!\n",
    "\n",
    "Run the cell to view the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #5:** Drop month, and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_sin'] = np.sin(df.day*(2.*np.pi/31))\n",
    "df['day_cos'] = np.cos(df.day*(2.*np.pi/31))\n",
    "df['month_sin'] = np.sin((df.month-1)*(2.*np.pi/12))\n",
    "df['month_cos'] = np.cos((df.month-1)*(2.*np.pi/12))\n",
    "\n",
    "# TODO 5\n",
    "# TODO -- Your code here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll left to see the converted month and day coluumns.\n",
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook introduced a few concepts to improve data quality.  We resolved missing values, converted the Date feature column to a datetime format, renamed feature columns, removed a value from a feature column, created one-hot encoding features, and converted temporal features to meaningful representations.  By the end of our lab, we gained an understanding as to why data should be \"cleaned\" and \"pre-processed\" before input into a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Basic Feature Engineering in Keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
